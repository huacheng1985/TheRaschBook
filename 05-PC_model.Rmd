# Partial Credit Model {#PC_model}

## Partial Credit Model 

### Recall: Rating Scale Model Key Features

- Same rating scale category structure across items

- Same Distance between categories on the logit scale

- Same number of categories across items

- Thresholds can be disordered

### Motivation for the Partial Credit (PC) Model

- Some measurement contexts require multiple scale lengths

- Sometimes categories are not observed for certain items (or used by individual raters)

- Facilitates the empirical investigation of a common rating scale structure across items

### Partial Credit Model Formula

The Partial Credit Model [Masters, 1982](https://link.springer.com/article/10.1007/BF02296272#citeas) is generalization of the dichotomous Rasch Model. It provides estimates of Person locations, Item difficulties, and Thresholds specific to each item.

Partial Credit Model Equation

$$ln\left[\frac{P_{n_i(xi=k)}}{P_{n_i(xi=k-1)}}\right]=\theta_{n}-\delta_{i}-\tau_{ik}$$

In the PC model, Thresholds($τ_{k}$) are estimated empirically for each element of one facet, such as items. They are not necessarily evenly spaced or ordered as expected. In contrast to the RS model, the location and relative distance between thresholds is estimated separately for each item.

## R-Lab: Rasch Partial Credit Model with "eRm" package
For the Partial Credit Model, we will continue to work with the subset of the Braun (1988) essay data that we explored in the last Chapter. In this case, we will use "eRm" package.

### Prepare the R package & the data
```{r}
library(readr) # To import the data
library(eRm) # For running the Partial Credit Model
library(plyr) # For plot the Item characteristic curves
library(WrightMap)# For plot the variable map
```

> Data Information

- The original data collection design is described by Braun (1988). The original dataset includes ratings for 32 students by 12 raters on three separate essay compositions. For this lab, we will look at the data from Essay 1. For ease of interpretation, the essay ratings from the original dataset have been recoded from nine categories to three categories (0 = low achievement, 1 = middle achievement; 2 = high achievement).

- In our analysis, we will treat the 12 raters as 12 polytomous “items” that share the three-category rating scale structure.

- Raters with high “difficulty” calibrations can be interpreted as severe – these raters assign low scores more often. Raters with low “difficulty” calibrations can be interpreted as lenient – these raters assign high scores more often.


```{r message=FALSE}
# Load the data
braun_data <- read_csv("braun data.csv")
head(braun_data)
# Preview the data using the summary function
summary(braun_data)
# Trim the data because we only need the response matrix.
PC_data <- braun_data[,-1]
# Subtract 1 from observations so that the lowest category is 0 (required for eRm)
PC_data_balanced <- PC_data-1
```

### R-Lab: Partial Credit Model with "eRm" package

```{r}
# Run the Partial Credit Model
PC_model <- PCM(PC_data_balanced)
# Check the result
summary(PC_model)
```

### Wright Map & Expected Response Curves & Item characteristic curves 
Wright Map or Variable Map
```{r}
# Plot the Variable Map
plotPImap(PC_model)
```

Item characteristic curves
```{r}
plotICC(PC_model, ask = FALSE)
```

### Examine item difficulty and threshold SEs

```{r}
### Examine item difficulty values:
item.estimates <- thresholds(PC_model)
item.estimates
item_difficulty <- item.estimates[["threshtable"]][["1"]]
item_difficulty

## Get threshold SEs values:
item.se <- item.estimates$se.thresh
item.se
```

### Examine Person locations (theta) and SEs
```{r}
# Standard errors for theta estimates:
person.locations.estimate <- person.parameter(PC_model)
summary(person.locations.estimate)
# Build a table for person locations
person_theta <- person.locations.estimate$theta.table
person_theta
```
### Exam the item and person fit statistics
```{r}
item.fit <- itemfit(person.locations.estimate)
item.fit
item.fit.table <- cbind(item.fit[["i.outfitMSQ"]],item.fit[["i.infitMSQ"]],item.fit[["i.infitMSQ"]],item.fit[["i.infitZ"]])
pfit <- personfit(person.locations.estimate)
pfit
person.fit.table <- cbind(pfit[["p.outfitMSQ"]],pfit[["p.outfitMSQ"]],pfit[["p.outfitMSQ"]],pfit[["p.outfitMSQ"]])
```

### Calculate the Person/Item Separation Reliability

As we mentioned in the previous chapter \@ref{Reliability}, Person/Item separation reliability is the estimate of how well we can differentiate individual items, persons, or other elements on the latent variable. Since not all the R packages include both separation reliability, the following is the example of calculating the Person/Item separation reliability.

We use the "braun_data" as an example:

#### Calculate the Item Separation Reliability

```{r}
# ===================================
# compute item separation reliability
# ===================================

# Get Item scores
ItemScores <- colSums(PC_data_balanced)

# Get Item SD
ItemSD <- apply(PC_data_balanced,2,sd)

# Calculate the se of the Item
ItemSE <- ItemSD/sqrt(length(ItemSD))

# compute the Observed Variance (also known as Total Person Variability or Squared Standard Deviation)
SSD.ItemScores <- var(ItemScores)

# compute the Mean Square Measurement error (also known as Model Error variance)
Item.MSE <- sum((ItemSE)^2) / length(ItemSE)

# compute the Item Separation Reliability
item.separation.reliability <- (SSD.ItemScores-Item.MSE) / SSD.ItemScores
item.separation.reliability
```

#### Calculate the Person Separation Reliability

```{r}
# ===================================
# compute person separation reliability
# ===================================

# Get Person scores
PersonScores <- rowSums(PC_data_balanced)

# Get Person SD
PersonSD <- apply(PC_data_balanced,1,sd)

# Calculate the se of the Person
PersonSE <- PersonSD/sqrt(length(PersonSD))

# compute the Observed Variance (also known as Total Person Variability or Squared Standard Deviation)
SSD.PersonScores <- var(PersonScores)

# compute the Mean Square Measurement error (also known as Model Error variance)
Person.MSE <- sum((PersonSE)^2) / length(PersonSE)

# compute the Person Separation Reliability
person.separation.reliability <- (SSD.PersonScores-Person.MSE) / SSD.PersonScores
person.separation.reliability
```

### Exercise
Can you plot the Standardized Residuals for our PC model? 
(Tips: You can use the R code from previous chapter, they're the same)

## Supplmentary Learning Materials 

[Braun, H. I. (1988). Understanding Scoring Reliability: Experiments in Calibrating Essay Readers. Journal of Educational and Behavioral Statistics, 13(1), 1–18.](http://doi.org/10.3102/10769986013001001) 

[Masters, G.N. A rasch model for partial credit scoring. Psychometrika 47, 149–174 (1982). https://doi.org/10.1007/BF02296272](https://link.springer.com/article/10.1007/BF02296272#citeas)









